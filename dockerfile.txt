# Use Ubuntu as the base image
FROM ubuntu:20.04

# Set environment variables for Airflow home, virtual environment, and PostgreSQL
ENV AIRFLOW_HOME=/opt/airflow
ENV AIRFLOW_VENV=/opt/airflow_venv
ENV POSTGRES_HOST=postgres
ENV POSTGRES_PORT=5432
ENV POSTGRES_USER=airflow
ENV POSTGRES_PASSWORD=airflow
ENV POSTGRES_DB=airflow_db

# Set the default shell to bash and disable interactive prompts for apt-get
SHELL ["/bin/bash", "-c"]
ARG DEBIAN_FRONTEND=noninteractive

# Update Ubuntu and install necessary packages
RUN apt-get update && apt-get install -y \
    python3.8 \
    python3.8-venv \
    python3.8-dev \
    postgresql-client \
    build-essential \
    vim \
    curl \
    sudo \
    netcat \
    git

# Create the Airflow home directory
RUN mkdir -p $AIRFLOW_HOME

# Create a virtual environment for Airflow
RUN python3 -m venv $AIRFLOW_VENV

# Activate the virtual environment and upgrade pip using the specified index URL
RUN source $AIRFLOW_VENV/bin/activate && \
    pip install --upgrade pip --index-url https://vagrant:vagrant@gbmt-nexus.prd.fx.gbm.cloud.uk.hsbc/repository/pypi-group/simple --trusted-host efx-nexus.systems.uk.hsbc:8084

# Install Apache Airflow without the constraints file as per your steps
RUN source $AIRFLOW_VENV/bin/activate && \
    pip install apache-airflow[postgres,celery,redis,crypto,ssh]==2.8.0 --index-url https://vagrant:vagrant@gbmt-nexus.prd.fx.gbm.cloud.uk.hsbc/repository/pypi-group/simple --trusted-host efx-nexus.systems.uk.hsbc:8084

# Install psycopg2 as per your steps
RUN source $AIRFLOW_VENV/bin/activate && \
    pip install apache-airflow[psycopg2]==2.8.0 --index-url https://vagrant:vagrant@gbmt-nexus.prd.fx.gbm.cloud.uk.hsbc/repository/pypi-group/simple --trusted-host efx-nexus.systems.uk.hsbc:8084

# Install Spark provider as per your steps
RUN source $AIRFLOW_VENV/bin/activate && \
    pip install apache-airflow-providers-apache-spark==2.1.3 --index-url https://vagrant:vagrant@gbmt-nexus.prd.fx.gbm.cloud.uk.hsbc/repository/pypi-group/simple --trusted-host efx-nexus.systems.uk.hsbc:8084 --cache-dir=/opt/airflow/cache/

# Expose the required Airflow ports
EXPOSE 8080 8793

# Copy over the Airflow configuration (use env variables for PostgreSQL)
COPY airflow.cfg $AIRFLOW_HOME/airflow.cfg

# Initialize the Airflow database using environment variables for Postgres
RUN source $AIRFLOW_VENV/bin/activate && \
    airflow db init

# Set up the Airflow admin user as per your steps
RUN source $AIRFLOW_VENV/bin/activate && \
    airflow users create -u admin -f admin -l admin -p admin -r Admin -e admin@admin.com

# Copy the entrypoint script to manage starting the services
COPY entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# Set the entrypoint
ENTRYPOINT ["/entrypoint.sh"]

----------------------------------------

#!/bin/bash

# Activate the virtual environment
source /opt/airflow_venv/bin/activate

# Update the SQLAlchemy connection string based on environment variables
sed -i "s#sql_alchemy_conn = .*#sql_alchemy_conn = postgresql+psycopg2://$POSTGRES_USER:$POSTGRES_PASSWORD@$POSTGRES_HOST:$POSTGRES_PORT/$POSTGRES_DB#g" $AIRFLOW_HOME/airflow.cfg

# Check which role to run based on the AIRFLOW__ROLE variable
if [ "$AIRFLOW__ROLE" = "scheduler" ]; then
    echo "Starting Airflow Scheduler..."
    exec airflow scheduler
elif [ "$AIRFLOW__ROLE" = "webserver" ]; then
    echo "Starting Airflow Webserver..."
    exec airflow webserver --port 8080
else
    echo "No role specified, exiting."
    exit 1
fi

-----------------------------------------------

version: '3'
services:
    postgres:
    image: postgres:13
    environment:
        POSTGRES_USER: airflow
        POSTGRES_PASSWORD: airflow
        POSTGRES_DB: airflow_db
    volumes:
        - postgres_data:/var/lib/postgresql/data
    networks:
        - airflow_network

    airflow-webserver:
    build:
        context: .
        dockerfile: Dockerfile
    environment:
        POSTGRES_HOST: postgres
        POSTGRES_PORT: 5432
        POSTGRES_USER: airflow
        POSTGRES_PASSWORD: airflow
        POSTGRES_DB: airflow_db
        AIRFLOW__ROLE: webserver
    ports:
        - "8080:8080"
    volumes:
        - ./logs:/opt/airflow/logs
        - ./dags:/opt/airflow/dags
    depends_on:
        - postgres
    networks:
        - airflow_network

    airflow-scheduler:
    build:
        context: .
        dockerfile: Dockerfile
    environment:
        POSTGRES_HOST: postgres
        POSTGRES_PORT: 5432
        POSTGRES_USER: airflow
        POSTGRES_PASSWORD: airflow
        POSTGRES_DB: airflow_db
        AIRFLOW__ROLE: scheduler
    volumes:
        - ./logs:/opt/airflow/logs
        - ./dags:/opt/airflow/dags
    depends_on:
        - postgres
    networks:
        - airflow_network

volumes:
    postgres_data:
    driver: local

networks:
    airflow_network:
    driver: bridge


